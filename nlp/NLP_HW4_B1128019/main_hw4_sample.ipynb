{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5b9e718-2242-414a-a214-3893846a7fa9",
      "metadata": {
        "id": "c5b9e718-2242-414a-a214-3893846a7fa9"
      },
      "source": [
        "# Homework 4\n",
        "- 開始寫作業前，若使用 Colab 請先設定使用 GPU!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "yjBZJhc3NWx8",
      "metadata": {
        "id": "yjBZJhc3NWx8"
      },
      "outputs": [],
      "source": [
        "# 0. 安裝套件\n",
        "\n",
        "# !pip install torch==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ee80bdf9-c6cb-4e0a-83dd-df0535cb49dc",
      "metadata": {
        "id": "ee80bdf9-c6cb-4e0a-83dd-df0535cb49dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hjc/coSpace/NLP_HW4/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# 1. 載入套件\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import SpearmanCorrCoef, Accuracy, F1Score\n",
        "\n",
        "# Hugging Face PEFT\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from peft.utils.other import prepare_model_for_kbit_training\n",
        "\n",
        "# 客製化模組\n",
        "from dataset import SemevalDataset\n",
        "from model import MultiLabelModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f93d6a06-7f3a-4882-891a-3b1746ddb675",
      "metadata": {
        "id": "f93d6a06-7f3a-4882-891a-3b1746ddb675"
      },
      "outputs": [],
      "source": [
        "# 2. 設定參數\n",
        "\n",
        "MODEL_NAME = \"microsoft/deberta-large\" # \"bert-base-uncased\"\n",
        "LR = 1e-5\n",
        "NUM_EPOCHS = 3\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VAL_BATCH_SIZE = 8\n",
        "SAVE_DIR = \"./saved_models/\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not Path(SAVE_DIR).exists():\n",
        "    Path(SAVE_DIR).mkdir(parents=True, exist_ok=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "AmCavLFnPoMN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmCavLFnPoMN",
        "outputId": "c7c32b33-8b0b-45d2-9007-05b747e2d8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset example: \n",
            "{'sentence_pair_id': 1, 'premise': 'A group of kids is playing in a yard and an old man is standing in the background', 'hypothesis': 'A group of boys in a yard is playing and a man is standing in the background', 'relatedness_score': 4.5, 'entailment_judgment': 0} \n",
            "{'sentence_pair_id': 2, 'premise': 'A group of children is playing in the house and there is no man standing in the background', 'hypothesis': 'A group of kids is playing in a yard and an old man is standing in the background', 'relatedness_score': 3.200000047683716, 'entailment_judgment': 0} \n",
            "{'sentence_pair_id': 3, 'premise': 'The young boys are playing outdoors and the man is smiling nearby', 'hypothesis': 'The kids are playing outdoors near a man with a smile', 'relatedness_score': 4.699999809265137, 'entailment_judgment': 1}\n"
          ]
        }
      ],
      "source": [
        "# 3. 載入資料集與測試\n",
        "\n",
        "data_sample = SemevalDataset(split=\"train\").data[:3]\n",
        "print(f\"Dataset example: \\n{data_sample[0]} \\n{data_sample[1]} \\n{data_sample[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "RcIYq5AkPvgS",
      "metadata": {
        "id": "RcIYq5AkPvgS"
      },
      "outputs": [],
      "source": [
        "# 4. 載入 tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=\"./cache/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "Mianyqk2PXym",
      "metadata": {
        "id": "Mianyqk2PXym"
      },
      "outputs": [],
      "source": [
        "# 5. 將 batch 資料進行整理\n",
        "# 取出每筆資料的 'premise' 和 'hypothesis' 內容\n",
        "# 將內容進行 tokenization 換成 token_ids 後，轉成 tensors\n",
        "# 將 labels 也轉成 tensors\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # TODO1: 完成 collate_fn\n",
        "    # Write your code here\n",
        "    # Extract premise and hypothesis from each example\n",
        "    premises = [ex[\"premise\"] for ex in batch]\n",
        "    hypotheses = [ex[\"hypothesis\"] for ex in batch]\n",
        "    \n",
        "    encoded = tokenizer(\n",
        "        premises,\n",
        "        hypotheses,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # Prepare labels for regression (relatedness_score) and classification (entailment_judgment)\n",
        "    scores = torch.tensor([ex[\"relatedness_score\"] for ex in batch], dtype=torch.float)\n",
        "    labels = torch.tensor([ex[\"entailment_judgment\"] for ex in batch], dtype=torch.long)\n",
        "    # Map to the expected variable names\n",
        "    input_text = encoded\n",
        "    labels1 = scores\n",
        "    labels2 = labels\n",
        "    return input_text, labels1, labels2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3d1a3644-f37a-4233-be8b-7f125da22cac",
      "metadata": {
        "id": "3d1a3644-f37a-4233-be8b-7f125da22cac"
      },
      "outputs": [],
      "source": [
        "# 6. 建立 DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    SemevalDataset(split=\"train\"),\n",
        "    collate_fn=collate_fn,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    SemevalDataset(split=\"validation\"),\n",
        "    collate_fn=collate_fn,\n",
        "    batch_size=VAL_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4eb70a8d-92ba-4eb3-9b44-d61a2d863642",
      "metadata": {
        "id": "4eb70a8d-92ba-4eb3-9b44-d61a2d863642"
      },
      "outputs": [],
      "source": [
        "# 7. 設置 loss functions\n",
        "# 因為是 multi-output learning\n",
        "# 所以應該要有 2 種 loss functions\n",
        "\n",
        "loss_fn1 = torch.nn.MSELoss()\n",
        "loss_fn2 = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "298dea68-338f-4eaf-9962-19effbf7fe2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "298dea68-338f-4eaf-9962-19effbf7fe2b",
        "outputId": "ec411796-6809-4c5c-94dc-90e0c2844483"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hjc/coSpace/NLP_HW4/.venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# 8. 設置評估指標\n",
        "\n",
        "spc = SpearmanCorrCoef()\n",
        "acc = Accuracy(task=\"multiclass\", num_classes=3)\n",
        "f1 = F1Score(task=\"multiclass\", num_classes=3, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e5068972-d508-4403-8b1d-3ef50da5e6cf",
      "metadata": {
        "id": "e5068972-d508-4403-8b1d-3ef50da5e6cf"
      },
      "outputs": [],
      "source": [
        "# 9. 載入模型，並直接把模型送至 GPU\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = MultiLabelModel(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f20dd905-6a37-41f0-8f4d-ccbffa6745dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f20dd905-6a37-41f0-8f4d-ccbffa6745dc",
        "outputId": "f88b56f3-3a74-49cf-86ee-1dc7ba27e53b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "可訓練參數數量: 2752512 (0.67%)\n"
          ]
        }
      ],
      "source": [
        "# 10. 配置LoRA\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=16,                          # LoRA矩陣的秩\n",
        "    lora_alpha=32,                 # LoRA的縮放參數\n",
        "    lora_dropout=0.1,              # LoRA層的dropout率\n",
        "    bias=\"none\",                   # 是否包含偏置參數\n",
        "    target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"output.dense\"],  # 要應用LoRA的模塊\n",
        ")\n",
        "\n",
        "# 為主幹模型做準備\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# 將模型轉換為PEFT模型\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# 只訓練LoRA參數\n",
        "for name, param in model.named_parameters():\n",
        "    if \"lora\" not in name and \"regression_head\" not in name and \"classification_head\" not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# 印出可訓練參數的數量\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"可訓練參數數量: {trainable_params} ({trainable_params/total_params:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "sFUGpaprazmS",
      "metadata": {
        "id": "sFUGpaprazmS"
      },
      "outputs": [],
      "source": [
        "# 11. 載入模型與 optimizer\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "752579e4",
      "metadata": {
        "id": "752579e4"
      },
      "outputs": [],
      "source": [
        "# 12. 建立測試函數\n",
        "\n",
        "def do_test(\n",
        "    dataloader,\n",
        "    model,\n",
        "    loss_fn1,\n",
        "    loss_fn2,\n",
        "    mode=\"validation\",\n",
        "    cur_epoch=0,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "):\n",
        "    model.eval()\n",
        "    \n",
        "    pbar = tqdm(dataloader)\n",
        "    pbar.set_description(f\"{mode} epoch [{cur_epoch+1}/{NUM_EPOCHS}]\")\n",
        "\n",
        "    pred1 = torch.tensor([])\n",
        "    pred2 = torch.tensor([])\n",
        "    gt1 = torch.tensor([])\n",
        "    gt2 = torch.tensor([])\n",
        "    loss1 = 0\n",
        "    loss2 = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_text, labels1, labels2 in pbar:\n",
        "            outputs1, outputs2 = model(**input_text)\n",
        "\n",
        "            loss1 += loss_fn1(outputs1, labels1).item()\n",
        "            loss2 += loss_fn2(outputs2, labels2).item()\n",
        "\n",
        "            outputs1 = outputs1.squeeze()\n",
        "            outputs2 = torch.argmax(outputs2, dim=-1)\n",
        "            pred1 = torch.cat((pred1, outputs1.to(\"cpu\")), dim=-1)\n",
        "            pred2 = torch.cat((pred2, outputs2.to(\"cpu\")), dim=-1)\n",
        "            gt1 = torch.cat((gt1, labels1.to(\"cpu\")), dim=-1)\n",
        "            gt2 = torch.cat((gt2, labels2.to(\"cpu\")), dim=-1)\n",
        "\n",
        "    print(f\"Spearman Corr: {spc(pred1, gt1)} \\nAccuracy: {acc(pred2, gt2)} \\nF1 Score: {f1(pred2, gt2)}\")\n",
        "    loss1 /= len(dataloader)\n",
        "    loss2 /= len(dataloader)\n",
        "    return loss1, loss2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "92755704",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wrap validation loader 打包以避免一次將所有驗證集丟進GPU顯存，在我的本機上比較不會遇到OOM\n",
        "class ValLoaderDeviceWrapper:\n",
        "    def __init__(self, loader, device):\n",
        "        self.loader = loader\n",
        "        self.device = device\n",
        "    def __iter__(self):\n",
        "        for input_text, labels1, labels2 in self.loader:\n",
        "            input_text = {k: v.to(self.device) for k, v in input_text.items()}\n",
        "            labels1 = labels1.to(self.device)\n",
        "            labels2 = labels2.to(self.device)\n",
        "            yield input_text, labels1, labels2\n",
        "    def __len__(self):\n",
        "        return len(self.loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b3960260",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting baseline training (no LoRA)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Baseline Training epoch [1/3]:   0%|          | 0/563 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Baseline Training epoch [1/3]:  10%|▉         | 55/563 [00:12<01:52,  4.51it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m     loss2_b = loss_fn2(logits_b, labels2_b)\n\u001b[32m     19\u001b[39m     loss_b = loss1_b + loss2_b\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mloss_b\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     baseline_optimizer.step()\n\u001b[32m     22\u001b[39m val_loader_device = ValLoaderDeviceWrapper(val_loader, device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/coSpace/NLP_HW4/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/coSpace/NLP_HW4/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/coSpace/NLP_HW4/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Baseline (non-LoRA) 版本\n",
        "\n",
        "baseline_model = MultiLabelModel(MODEL_NAME).to(device)\n",
        "baseline_optimizer = AdamW(baseline_model.parameters(), lr=LR)\n",
        "print(\"Starting baseline training (no LoRA)...\")\n",
        "for ep_base in range(NUM_EPOCHS):\n",
        "    pbar_base = tqdm(train_loader)\n",
        "    pbar_base.set_description(f\"Baseline Training epoch [{ep_base+1}/{NUM_EPOCHS}]\")\n",
        "    baseline_model.train()\n",
        "    for batch in pbar_base:\n",
        "        baseline_optimizer.zero_grad()\n",
        "        input_text_b, labels1_b, labels2_b = batch\n",
        "        input_text_b = {k: v.to(device) for k, v in input_text_b.items()}\n",
        "        labels1_b = labels1_b.to(device)\n",
        "        labels2_b = labels2_b.to(device)\n",
        "        score_b, logits_b = baseline_model(**input_text_b)\n",
        "        loss1_b = loss_fn1(score_b, labels1_b)\n",
        "        loss2_b = loss_fn2(logits_b, labels2_b)\n",
        "        loss_b = loss1_b + loss2_b\n",
        "        loss_b.backward()\n",
        "        baseline_optimizer.step()\n",
        "    val_loader_device = ValLoaderDeviceWrapper(val_loader, device)\n",
        "    val_loss1_b, val_loss2_b = do_test(\n",
        "        val_loader_device,\n",
        "        baseline_model,\n",
        "        loss_fn1,\n",
        "        loss_fn2,\n",
        "        mode=\"baseline_validation\",\n",
        "        cur_epoch=ep_base,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db45e56-e331-4b90-9709-6747ad82768c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1db45e56-e331-4b90-9709-6747ad82768c",
        "outputId": "8caf9c46-02d9-4a04-eb0b-59e6898120d7"
      },
      "outputs": [],
      "source": [
        "# LoRA 版本\n",
        "for ep in range(NUM_EPOCHS):\n",
        "    pbar = tqdm(train_loader)\n",
        "    pbar.set_description(f\"Training epoch [{ep+1}/{NUM_EPOCHS}]\")\n",
        "    model.train()\n",
        "    for batch in pbar:\n",
        "        # TODO3: Write the training loop\n",
        "        # Write your code here\n",
        "        # train your model\n",
        "        # clear gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Unpack tuple from collate_fn\n",
        "        input_text, labels1, labels2 = batch\n",
        "\n",
        "        # Move inputs and labels to device\n",
        "        input_text = {k: v.to(device) for k, v in input_text.items()}\n",
        "        labels1 = labels1.to(device)\n",
        "        labels2 = labels2.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        score_pred, logits_pred = model(**input_text)\n",
        "        # compute loss\n",
        "        loss1 = loss_fn1(score_pred, labels1)\n",
        "        loss2 = loss_fn2(logits_pred, labels2)\n",
        "        loss = loss1 + loss2\n",
        "        # back-propagation\n",
        "        loss.backward()\n",
        "        # model optimization\n",
        "        optimizer.step()\n",
        "\n",
        "    # Create a generator that moves validation batches to the correct device\n",
        "    def val_batches_on_device():\n",
        "        for batch in val_loader:\n",
        "            input_text, labels1, labels2 = batch\n",
        "            input_text = {k: v.to(device) for k, v in input_text.items()}\n",
        "            labels1 = labels1.to(device)\n",
        "            labels2 = labels2.to(device)\n",
        "            yield input_text, labels1, labels2\n",
        "\n",
        "    val_loss1, val_loss2 = do_test(\n",
        "        val_batches_on_device(),\n",
        "        model,\n",
        "        loss_fn1,\n",
        "        loss_fn2,\n",
        "        mode=\"validation\",\n",
        "        cur_epoch=ep,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "    )\n",
        "    torch.save(model, f'./saved_models/ep{ep}.ckpt')\n",
        "    print(f\"Model saved to {SAVE_DIR}ep{ep}.ckpt!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qvrV1wX3QHVe",
      "metadata": {
        "id": "qvrV1wX3QHVe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
